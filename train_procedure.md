<center><h3><font style='font-family:楷体'> 图像定位任务(location)过程 </font></h3></center>

##### Version 1：

​	改编版（简陋版） $YOLO v1$，使用基础卷积、残差网络、线性层的形式直接进行目标检测的预测，损失函数使用 $MSE$，优化器采用 $SGD$。效果十分不尽人意，预测框的波动非常大，几乎看不出跟随物体移动的迹象。失败！

​	这里需要注意的是，使用 $ReLU$ 函数会导致梯度爆炸，$loss$ 的数值直接变成 $nan$，故转而使用 $Tanh$，解决问题。

​	我认为主要的问题在于：

（1）图像的尺寸为 180 * 240，不是正方形；初始的唯一一层卷积层会将图像处理成 56 * 56 大小，这个过程会损失很多信息。

（2）损失函数不合理。

（3）最终对于分类的处理不合理

​	解决方法：

（1）采用补全的办法得到正方形图像进行训练。

（2）准备继续研究 $YOLO v1$ 的算法原理，然后使用 $YOLO v1$ 作为基本模型进行目标检测。这里不需要进行置信度的处理，因为始终只有一个目标。

##### version 2：

（1）采用填充的方法将数据从 240 * 180 转换为 240 * 240，编写转换函数

（2）重新编写网络的标签，结果为
$$
t_x=\frac{x-grid\_size*i}{grid\_size}\\
t_y=\frac{y-grid\_size*j}{grid\_szie}\\
t_w=\ln{b_w/w}\\
t_h=\ln{b_h/h}
$$


（3）重新编写损失函数：$loss=5*((\Delta t_x)^2+(\Delta t_y)^2+ (\Delta t_w)^2+(\Delta t_h)^2)+10*(\Delta c)^2_{in}+0.5*(\Delta c)^2_{out}$

（4）选用 Sigmoid 激活函数

​	效果仍然不佳，预测的位置偏差很大，很疑惑。最关键的问题在于整体上对于物体框中心位置预测很不准确，这是最需要修改的部分。

##### version 3：

（1）取缔全连接层，采用全卷积的形式，最终输出采用 contiguous().view() 

（2）采用 $LeakyReLU$ 激活函数

（3）选择 Adam 优化器

​	失败了，预测框还是到处乱跳

##### version 4：

（1）直接使用 4 维坐标值进行训练

​	还是不行，跳动很明显，误差很大。

##### version 5：

​	依然直接采用预测 4 个坐标值的方式，但是==解决了两个重大失误：==

（1）没有使用 label_transforming 接口对标签进行预处理，直接忽视了这个接口。

（2）train_loader 的顺序是被 shuffle 过的，序号完全对不上，所以不能够直接进行预测。这是一个重大错误。

​	然后通过直接训练输出坐标得到了相对较好的结果。

​	==战战兢兢，如临深渊，如履薄冰！==

##### version 6：

​	采用了仿 $YOLO$ net 的模式，修正了之前的错误，完善了算法。

（1）采用了 learning rate 先增加再减小的方式分别训练了 20，50，60 个 epoch，$lr=1e-4,5e-4,1e-5$

（2）观察到训练集中有的图片上已经没有需要识别的物体了，但是还是给出了 label。这里将这一小部分训练集直接剔除，不参加训练。

​	记 $YOLO-like$ 和 $locate\ net$ 分别为 $a1$， $a2$。

##### version 7：

​	$a1\ final$：

（1）给输出标签的 confidence 取一阈值，若 confidence 低于阈值则不输出预测框，即认为图像中没有该物体。

（2）完成了全部的训练集和测试集的预测，准备在输出图像中计算 $IoU$，这并不是一件很难的任务。

##### version 8 final：

##### 	$a1$ 确定，$a2$ 修改。

（1）在全连接层中加入 $dropout$，但是效果并不好，因为全连接层的底层本来就维度就很少（7 * 7 * 4 -> 4），如果再进行 $dropout$，那么有效参数的数量就会减少很多。

（2）不准备继续完成 $a2$ 了：网络的深度已经十分足够了，在使用了很多 $res\_block$ 的情况下，仍然不能够完成对训练集的高精度定位，说明这样的网络以及标签设置并不好。

（3）$a1$ 如果能够再调整（网络架构或者标签设置）可能能够达到更好的效果，暂时就这样吧，训练集或者测试集的效果都已经相当不错了。

​	这次的目标定位（location）算是完美收官了。之前作为作业时，要完成的任务，我在当时就弄错了，把目标检测和定位搞错了。但是即使我那时候已经知道了所谓的“定位”，我也没有十足的把握能够在当时完成这次任务。不知道 $res\_block$ 的情况下，估计连 $a2$ 版本的效果都很差。可能如果直接用传统 $CNN$ 的架构说不定也能够完成这次任务。但是这些都是后话了。
